id,citekey,title,authors,year,month,journal,book_title,publisher,institution,volume,number,pages,note,keywords,url,code,pdf,image,thumbnail,doi,external,abstract,isbn,type_id
64.0,,Enabling Kubernetes Orchestration of Mixed-Criticality Software for Autonomous Mobile Robots,F. Lumpp; F. Fummi; H. D. Patel; N. Bombieri,2024,,IEEE Transactions on Robotics,,IEEE,"Department of Engineering for Innovation Medicine, University of Verona, Verona, Italy; Department of Engineering for Innovation Medicine, University of Verona, Verona, Italy; Department of Electrical and Computer Engineering, University of Waterloo, Waterloo, ON, Canada; Department of Engineering for Innovation Medicine, University of Verona, Verona, Italy",0,0,,,Real-time systems;Software;Containers;Standards;Autonomous robots;Mobile robots;Edge computing,,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10323202,,,10.1109/TRO.2023.3334642,False,"Containerization and orchestration have become two key requirements in software development best practices. Containerization allows for better resource utilization, platform-independent development, and secure deployment of software. Orchestration automates the deployment, networking, scaling, and availability of containerized workloads and services. While containerization is increasingly being adopted in the robotic community, the use of task orchestration platforms (e.g., Kubernetes) is still an open challenge. The biggest limitation is due to the fact that state-of-the-art orchestrators do not support real-time (RT) containers, while advanced robotic software often consists of a mix of heterogeneous tasks (i.e., ROS nodes) with different levels of temporal constraints (i.e., mixed-criticality systems). This work addresses this challenge by presenting RT-Kube, a platform that extends the de-facto reference standard for container orchestration, Kubernetes, to schedule tasks with mixed-criticality requirements. It implements monitoring of tasks and detects missed deadlines for those with RT constraints. It selects low-priority tasks to be migrated at runtime to different units of the computing cluster to free resources and recover from temporal violations. We present quantitative experimental results on the software implementing the mission of a Robotnik RB-Kairos mobile robot to demonstrate the effectiveness of the proposed approach. The source code is publicly available on GitHub.",,1
65.0,,"Learn Fast, Segment Well: Fast Object Segmentation Learning on the iCub Robot",F. Ceola; E. Maiettini; G. Pasquale; G. Meanti; L. Rosasco; L. Natale,2022,,IEEE Transactions on Robotics,,IEEE,"Humanoid Sensing and Perception (HSP), Istituto Italiano di Tecnologia (IIT), Genoa, Italy; Humanoid Sensing and Perception (HSP), Istituto Italiano di Tecnologia (IIT), Genoa, Italy; Humanoid Sensing and Perception (HSP), Istituto Italiano di Tecnologia (IIT), Genoa, Italy; Laboratory for Computational and Statistical Learning (LCSL), Machine Learning Genoa Center (MaLGa), and the Dipartimento di Informatica, Bioingegneria, Robotica e Ingegneria dei Sistemi (DIBRIS), University of Genova, Genoa, Italy; Laboratory for Computational and Statistical Learning (LCSL), Machine Learning Genoa Center (MaLGa), and the Dipartimento di Informatica, Bioingegneria, Robotica e Ingegneria dei Sistemi (DIBRIS), University of Genova, Genoa, Italy; Humanoid Sensing and Perception (HSP), Istituto Italiano di Tecnologia (IIT), Genoa, Italy",0,0,,,Robots;Training;Pipelines;Feature extraction;Proposals;Image segmentation;Object detection,,https://github.com/hsp-iit/online-detection,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9863699,,,10.1109/TRO.2022.3164331,False,"The visual system of a robot has different requirements depending on the application: it may require high accuracy or reliability, be constrained by limited resources, or need fast adaptation to dynamically changing environments. In this article, we focus on the instance segmentation task and provide a comprehensive study of different techniques that allow adapting an object segmentation model in the presence of novel objects or different domains. We propose a pipeline for fast instance segmentation learning designed for robotic applications where data come in stream. It is based on an hybrid method leveraging on a pre-trained convolutional neural network for feature extraction and fast-to-train Kernel-based classifiers. We also propose a training protocol that allows to shorten the training time by performing feature extraction during the data acquisition. We benchmark the proposed pipeline on two robotics datasets and we deploy it on a real robot, i.e., the iCub humanoid. To this aim, we adapt our method to an incremental setting in which novel objects are learned online by the robot. The code to reproduce the experiments is publicly available on GitHub.11[Online]. Available: https://github.com/hsp-iit/online-detection",,1
66.0,,FAST-LIO2: Fast Direct LiDAR-Inertial Odometry,W. Xu; Y. Cai; D. He; J. Lin; F. Zhang,2022,,IEEE Transactions on Robotics,,IEEE,"Mechatronics and Robotic Systems (MaRS) Laboratory, Department of Mechanical Engineering, University of Hong Kong, Hong Kong SAR, China; Mechatronics and Robotic Systems (MaRS) Laboratory, Department of Mechanical Engineering, University of Hong Kong, Hong Kong SAR, China; Mechatronics and Robotic Systems (MaRS) Laboratory, Department of Mechanical Engineering, University of Hong Kong, Hong Kong SAR, China; Mechatronics and Robotic Systems (MaRS) Laboratory, Department of Mechanical Engineering, University of Hong Kong, Hong Kong SAR, China; Mechatronics and Robotic Systems (MaRS) Laboratory, Department of Mechanical Engineering, University of Hong Kong, Hong Kong SAR, China",0,0,,,Laser radar;Robots;Real-time systems;Feature extraction;Data structures;Point cloud compression;Kalman filters,,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9697912,,,10.1109/TRO.2022.3141876,False,"This article presents FAST-LIO2: a fast, robust, and versatile LiDAR-inertial odometry framework. Building on a highly efficient tightly coupled iterated Kalman filter, FAST-LIO2 has two key novelties that allow fast, robust, and accurate LiDAR navigation (and mapping). The first one is directly registering raw points to the map (and subsequently update the map, i.e., mapping) without extracting features. This enables the exploitation of subtle features in the environment and, hence, increases the accuracy. The elimination of a hand-engineered feature extraction module also makes it naturally adaptable to emerging LiDARs of different scanning patterns; the second main novelty is maintaining a map by an incremental k-dimensional (k-d) tree data structure, incremental k-d tree (ikd-Tree), that enables incremental updates (i.e., point insertion and delete) and dynamic rebalancing. Compared with existing dynamic data structures (octree, R$^\ast$-tree, and nanoflann k-d tree), ikd-Tree achieves superior overall performance while naturally supports downsampling on the tree. We conduct an exhaustive benchmark comparison in 19 sequences from a variety of open LiDAR datasets. FAST-LIO2 achieves consistently higher accuracy at a much lower computation load than other state-of-the-art LiDAR-inertial navigation systems. Various real-world experiments on solid-state LiDARs with small field of view are also conducted. Overall, FAST-LIO2 is computationally efficient (e.g., up to 100 Hz odometry and mapping in large outdoor environments), robust (e.g., reliable pose estimation in cluttered indoor environments with rotation up to 1000 deg/s), versatile (i.e., applicable to both multiline spinning and solid-state LiDARs, unmanned aerial vehicle (UAV) and handheld platforms, and Intel- and ARM-based processors), while still achieving a higher accuracy than existing methods. Our implementation of the system FAST-LIO2 and the data structure ikd-Tree are both open-sourced on Github.",,1
67.0,,Empty Cities: A Dynamic-Object-Invariant Space for Visual SLAM,B. Bescos; C. Cadena; J. Neira,2021,,IEEE Transactions on Robotics,,IEEE,"Department of Computer Science and System Engineering, University of Zaragoza, Zaragoza, Spain; Mechanical and Process Engineering, ETH Zurich, Zurich, Switzerland; Instituto de Investigación en Ingeniería de Aragón, Universidad de Zaragoza, Zaragoza, Spain",0,0,,,Vehicle dynamics;Simultaneous localization and mapping;Task analysis;Semantics;Dynamics;Deep learning;Gallium nitride,,https://github.com/bertabescos/EmptyCities_SLAM,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9246713,,,10.1109/TRO.2020.3031267,False,"In this article, we present a data-driven approach to obtain the static image of a scene, eliminating dynamic objects that might have been present at the time of traversing the scene with a camera. The general objective is to improve vision-based localization and mapping tasks in dynamic environments, where the presence (or absence) of different dynamic objects in different moments makes these tasks less robust. We introduce an end-to-end deep learning framework to turn images of an urban environment that include dynamic content, such as vehicles or pedestrians, into realistic static frames suitable for localization and mapping. This objective faces two main challenges: detecting the dynamic objects, and inpainting the static occluded background. The first challenge is addressed by the use of a convolutional network that learns a multiclass semantic segmentation of the image. The second challenge is approached with a generative adversarial model that, taking as input the original dynamic image and the computed dynamic/static binary mask, is capable of generating the final static image. This framework makes use of two new losses, one based on image steganalysis techniques, useful to improve the inpainting quality, and another one based on ORB features, designed to enhance feature matching between real and hallucinated image regions. To validate our approach, we perform an extensive evaluation on different tasks that are affected by dynamic entities, i.e.,visual odometry, place recognition, and multiview stereo, with the hallucinated images. Code has been made available on https://github.com/bertabescos/EmptyCities_SLAM.",,1
68.0,,CPL-SLAM: Efficient and Certifiably Correct Planar Graph-Based SLAM Using the Complex Number Representation,T. Fan; H. Wang; M. Rubenstein; T. Murphey,2020,,IEEE Transactions on Robotics,,IEEE,"Department of Mechanical Engineering, Northwestern University, Evanston, IL, USA; Department of Computer Science, Northwestern Univerity, Evanston, IL, USA; Departments of Computer Science and Mechanical Engineering, Northwestern Univerity, Evanston, IL, USA; Department of Mechanical Engineering, Northwestern University, Evanston, IL, USA",0,0,,,Simultaneous localization and mapping;Optimization;Autonomous agents,,https://github.com/MurpheyLab/CPL-SLAM,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9143200,,,10.1109/TRO.2020.3006717,False,"In this article, we consider the problem of planar graph-based simultaneous localization and mapping (SLAM) that involves both poses of the autonomous agent and positions of observed landmarks. We present complex (CPL)-SLAM, an efficient and certifiably correct algorithm to solve planar graph-based SLAM using the complex number representation. We formulate and simplify planar graph-based SLAM as the maximum likelihood estimation on the product of unit complex numbers, and relax this nonconvex quadratic complex optimization problem to convex complex semidefinite programming (SDP). Furthermore, we simplify the corresponding complex SDP to Riemannian staircase optimization (RSO) on the complex oblique manifold that can be solved with the Riemannian trust region method. In addition, we prove that the SDP relaxation and RSO simplification are tight as long as the noise magnitude is below a certain threshold. The efficacy of this work is validated through applications of CPL-SLAM and comparisons with existing state-of-the-art methods on planar graph-based SLAM, which indicates that our proposed algorithm is capable of solving planar graph-based SLAM certifiably, and is more efficient in numerical computation and more robust to measurement noise than existing state-of-the-art methods. The C++ code for CPL-SLAM is available at https://github.com/MurpheyLab/CPL-SLAM.",,1
